<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#1c64f2"/><meta name="apple-mobile-web-app-title" content="Mohit Singh"/><meta name="application-name" content="Mohit Singh"/><meta name="msapplication-TileColor" content="#2d89ef"/><meta name="theme-color" content="#ffffff"/><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>A distributed link shortener | Blog of Mohit Singh</title><meta name="description" content="In my post about building building link-shortener, I discussed about how I attempted to build a fully functional link shortener. That worked well but I was left with several questions during my previous attempt."/><link href="https://mohitsingh.in/sitemap.xml" rel="sitemap" type="application/xml" title="Sitemap"/><meta content="wmG9n4x_BUWryqpD2K4wEF9Edfh_LNapQe-qfbv4D3o" name="google-site-verification"/><link rel="canonical" href="https://mohitsingh.in/code/a-distributed-link-shortner"/><meta name="next-head-count" content="7"/><link rel="preload" href="/_next/static/css/17108455eac6aad5c488.css" as="style"/><link rel="stylesheet" href="/_next/static/css/17108455eac6aad5c488.css" data-n-g=""/><link rel="preload" href="/_next/static/css/e1fe27d84a18852b7129.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e1fe27d84a18852b7129.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a54b4f32bdc1ef890ddd.js"></script><script src="/_next/static/chunks/webpack-715feba1dbc96f0c4f3f.js" defer=""></script><script src="/_next/static/chunks/framework-2191d16384373197bc0a.js" defer=""></script><script src="/_next/static/chunks/main-b9780dc6f4fa7abb3771.js" defer=""></script><script src="/_next/static/chunks/pages/_app-d164e74ceea89891f9ba.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...posts%5D-68cf0e6a6b64b0c1d37b.js" defer=""></script><script src="/_next/static/vLj-h1l1iYxo80BnxHitK/_buildManifest.js" defer=""></script><script src="/_next/static/vLj-h1l1iYxo80BnxHitK/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="flex flex-col flex-grow flex-shrink-0"><article class="w-full px-4 py-24" itemID="#" itemscope="" itemType="http://schema.org/BlogPosting"><header class="w-full mx-auto mb-12 text-center md:w-2/3"><h1 class="mb-3 text-4xl font-bold text-gray-700 md:leading-tight md:text-5xl" itemProp="headline" title="A distributed link shortener">A distributed link shortener</h1><p class="text-xs text-gray-600 md:text-sm">Written by<span class="font-medium text-gray-700" itemProp="author" itemscope="" itemType="http://schema.org/Person"><span itemProp="name"> <!-- -->Mohit Singh<!-- --> </span></span>on <time itemProp="datePublished dateModified" dateTime="Sat Sep 04 2021" pubdate="true">Sat Sep 04 2021</time></p></header><section class="mx-auto prose"><p>In my post about building <a href="/code/building-a-link-shortner">building link-shortener</a>, I discussed about how I attempted to build a fully functional link shortener. That worked well but I was left with several questions during my previous attempt —</p>
<ul>
<li>I never finished the dashboard despite of entire system being ready. With so many open source visualization tools <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, do I really need to build a custom dashboard ?</li>
<li>It was hard to scale and was still prone to collisions. Is there any way to have a faster but complete collision free system ?</li>
<li>Bloom-Filters did a good job, but is it a good generate IDs at request time ?</li>
</ul>
<p>There were several other questions as well and above all, I wanted to make this scalable. So, let's see how far I explored.</p>
<h2>Breaking into pieces</h2>
<p>After some thinking and punching through walls, I came with a seemingly distributed architecture. I decided to remove authentication and custom dashboard and planned to use external tools directly connected to database for visualization. My architecture has three services —</p>
<ul>
<li><strong>Generator</strong> - The job of this guy is to generate IDs and pass them to those who request.</li>
<li><strong>Director</strong> - This one directs people to correct links and passes their information to our timeseries database.</li>
<li><strong>Creator</strong> - This one is for handling creation and other modifications of short links.</li>
</ul>
<h3>Generator</h3>
<p>The one took longer than I expected. It further contains several pieces —</p>
<ul>
<li><strong>Bucket</strong> - A custom data-structure which contains a two dimensional slice for holding IDs, the fist dimension is for number of buckets and second is for capacity and a synchronized map to keep record of bucket states.</li>
<li><strong>Bloom</strong> - A thread-safe wrapper around bloom-filter implementation I was using.</li>
<li><strong>Factory</strong> - The primary pieces which exposes gRPC method to retrieve one bucket full of IDs at time and fills buckets as they get empty</li>
</ul>
<p>Now, this service keeps generating IDs as we request more IDs from It. This way, we always end up with enough pre-generated IDs with no collisions.</p>
<p>To scale it, we can make our bloom-filters distributed and use gRPC for it's operations, but for now it works well even for generating millions of IDs in my limited testing.</p>
<h3>Creator</h3>
<p>Most of the code from old monolith was reused to build this. Although, I had to introduce several new pieces to make it horizontally scalable —</p>
<ul>
<li><strong>Ingestor</strong> handles batch insertion of created links based on a limited and a timed fallback.</li>
<li><strong>Reserve</strong> keeps a bucket full of IDs and when a bucket gets empty, it calls the generator to request new bucket through gRPC.</li>
</ul>
<p>With a request handler combined with this, I fired <code class="language-text">wrk</code> only to find that I had several collisions. Since slices don't always modify internal array in heap, I suspected that my slice operation on bucket was concurrent causing it to return duplicate IDs. A mutex later, it was fixed and then came another issue. Several IDs were failing to generate. It was easy to spot as the number of failed requests was same as no of requested bucket. I added some delay in main request when bucket was requested. Now, every request was processed without failure.</p>
<p>The system was able to create 7-8 Million links during several one minute tests. It was a huge improvement over my previous attempt which could only generate around 2-3 Million links in a minute with same resource usage. Added benefit with this is that I can scale this service horizontally along with some database replicas or by switching to Cassandra or Scylla.</p>
<h3>Director</h3>
<p>Director was rather simple since it was already independent of rest of the system. All I had to do was to decouple it from old monolith. After adding redis as caching layer over postgres I was able to double request handling. I excepted better but perhaps running everything on a single system for wasn't a good idea for this test.</p>
<p>The good is that this too scales horizontally, So all we need to is to grow machines and instances to handle more requests.</p>
<h2>Conclusion</h2>
<p>The code is <a href="https://github.com/mohitsinghs/wormholes" rel="nofollow noopener noreferrer">open source</a>, so you can always have a look but it's lacking pieces like k8s config at the time of writing. I am still curious what other ways are there to make this even more fast and reliable. I sticked to postgres and timescale but for huge traffic, I wonder how Cassandra, Scylla and Druid will perform compared to these. I learned a few memory and optimization techniques during this and witnessed my failures multiple times. Learning is a continuos process like workout. We can never expect to get done either.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote">like metabase, superset, redash etc<a href="#fnref1" class="footnote-back" role="doc-backlink">↩</a></li>
</ol>
</section>
</section></article></main><footer class="w-full py-4 text-center"><p class="text-xs text-gray-700">Copyright © 2021 Mohit Singh</p></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"title":"Code","posts":[{"title":"A distributed link shortener","author":"Mohit Singh","date":"2021-09-04","excerpt":"In my post about building building link-shortener, I discussed about how I attempted to build a fully functional link shortener. That worked well but I was left with several questions during my previous attempt.","slug":"a-distributed-link-shortner","link":"code/a-distributed-link-shortner"},{"title":"On frontend tooling","author":"Mohit Singh","date":"2021-08-21","excerpt":"One thing I keep saying to people, Love it or hate it but it's still in your mind.. Same happens with me and frontend tooling. When I started creating websites and was recovering from my android madness, the state of frontend tooling was way more complex than today.","slug":"on-frontend-tooling","link":"code/on-frontend-tooling"},{"title":"Laws for Software Engineers","author":"Mohit Singh","date":"2021-08-12","excerpt":"Software Engineering is not always fun and sometimes we face results we never except. And then, there exits a whole set of principles and laws people came up with over time to answer these failures and patterns.","slug":"laws-for-software-engineers","link":"code/laws-for-software-engineers"},{"title":"Story of njk, a tool mistreated","author":"Mohit Singh","date":"2021-08-07","excerpt":"In 2014, I decide to build static websites for others in need, voluntarily. I didn't know much about web technologies but after a little research, I found that static-site-generators were a thing.","slug":"njk","link":"code/njk"},{"title":"Building a link shortener","author":"Mohit Singh","date":"2021-07-26","excerpt":"A while back, I was asked to write a link shortener for a startup. It took me a day to come up with a production ready version but I warned them about collisions and other possible limitations.","slug":"building-a-link-shortner","link":"code/building-a-link-shortner"},{"title":"Not The Tailwind Way","author":"Mohit Singh","date":"2021-07-25","excerpt":"I love Tailwind and it solves a lot of pain points I had writing CSS. The problem is, it pollutes my HTML well beyond refactoring and I've to be lucky to get something broken fixed.","slug":"no-tailwind","link":"code/no-tailwind"},{"title":"Hello","author":"Mohit Singh","date":"2021-07-21","excerpt":"I tried blogging a few times during last 8 years, but ended up stopping, but now I finally feel like I have courage to write things in my mind.","slug":"hello","link":"code/hello"}],"post":{"title":"A distributed link shortener","author":"Mohit Singh","date":"2021-09-04","excerpt":"In my post about building building link-shortener, I discussed about how I attempted to build a fully functional link shortener. That worked well but I was left with several questions during my previous attempt.","slug":"a-distributed-link-shortner","link":"code/a-distributed-link-shortner","content":"\u003cp\u003eIn my post about building \u003ca href=\"/code/building-a-link-shortner\"\u003ebuilding link-shortener\u003c/a\u003e, I discussed about how I attempted to build a fully functional link shortener. That worked well but I was left with several questions during my previous attempt —\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eI never finished the dashboard despite of entire system being ready. With so many open source visualization tools \u003ca href=\"#fn1\" class=\"footnote-ref\" id=\"fnref1\" role=\"doc-noteref\"\u003e\u003csup\u003e1\u003c/sup\u003e\u003c/a\u003e, do I really need to build a custom dashboard ?\u003c/li\u003e\n\u003cli\u003eIt was hard to scale and was still prone to collisions. Is there any way to have a faster but complete collision free system ?\u003c/li\u003e\n\u003cli\u003eBloom-Filters did a good job, but is it a good generate IDs at request time ?\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere were several other questions as well and above all, I wanted to make this scalable. So, let's see how far I explored.\u003c/p\u003e\n\u003ch2\u003eBreaking into pieces\u003c/h2\u003e\n\u003cp\u003eAfter some thinking and punching through walls, I came with a seemingly distributed architecture. I decided to remove authentication and custom dashboard and planned to use external tools directly connected to database for visualization. My architecture has three services —\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eGenerator\u003c/strong\u003e - The job of this guy is to generate IDs and pass them to those who request.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDirector\u003c/strong\u003e - This one directs people to correct links and passes their information to our timeseries database.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCreator\u003c/strong\u003e - This one is for handling creation and other modifications of short links.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eGenerator\u003c/h3\u003e\n\u003cp\u003eThe one took longer than I expected. It further contains several pieces —\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBucket\u003c/strong\u003e - A custom data-structure which contains a two dimensional slice for holding IDs, the fist dimension is for number of buckets and second is for capacity and a synchronized map to keep record of bucket states.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBloom\u003c/strong\u003e - A thread-safe wrapper around bloom-filter implementation I was using.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFactory\u003c/strong\u003e - The primary pieces which exposes gRPC method to retrieve one bucket full of IDs at time and fills buckets as they get empty\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow, this service keeps generating IDs as we request more IDs from It. This way, we always end up with enough pre-generated IDs with no collisions.\u003c/p\u003e\n\u003cp\u003eTo scale it, we can make our bloom-filters distributed and use gRPC for it's operations, but for now it works well even for generating millions of IDs in my limited testing.\u003c/p\u003e\n\u003ch3\u003eCreator\u003c/h3\u003e\n\u003cp\u003eMost of the code from old monolith was reused to build this. Although, I had to introduce several new pieces to make it horizontally scalable —\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eIngestor\u003c/strong\u003e handles batch insertion of created links based on a limited and a timed fallback.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReserve\u003c/strong\u003e keeps a bucket full of IDs and when a bucket gets empty, it calls the generator to request new bucket through gRPC.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWith a request handler combined with this, I fired \u003ccode class=\"language-text\"\u003ewrk\u003c/code\u003e only to find that I had several collisions. Since slices don't always modify internal array in heap, I suspected that my slice operation on bucket was concurrent causing it to return duplicate IDs. A mutex later, it was fixed and then came another issue. Several IDs were failing to generate. It was easy to spot as the number of failed requests was same as no of requested bucket. I added some delay in main request when bucket was requested. Now, every request was processed without failure.\u003c/p\u003e\n\u003cp\u003eThe system was able to create 7-8 Million links during several one minute tests. It was a huge improvement over my previous attempt which could only generate around 2-3 Million links in a minute with same resource usage. Added benefit with this is that I can scale this service horizontally along with some database replicas or by switching to Cassandra or Scylla.\u003c/p\u003e\n\u003ch3\u003eDirector\u003c/h3\u003e\n\u003cp\u003eDirector was rather simple since it was already independent of rest of the system. All I had to do was to decouple it from old monolith. After adding redis as caching layer over postgres I was able to double request handling. I excepted better but perhaps running everything on a single system for wasn't a good idea for this test.\u003c/p\u003e\n\u003cp\u003eThe good is that this too scales horizontally, So all we need to is to grow machines and instances to handle more requests.\u003c/p\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eThe code is \u003ca href=\"https://github.com/mohitsinghs/wormholes\" rel=\"nofollow noopener noreferrer\"\u003eopen source\u003c/a\u003e, so you can always have a look but it's lacking pieces like k8s config at the time of writing. I am still curious what other ways are there to make this even more fast and reliable. I sticked to postgres and timescale but for huge traffic, I wonder how Cassandra, Scylla and Druid will perform compared to these. I learned a few memory and optimization techniques during this and witnessed my failures multiple times. Learning is a continuos process like workout. We can never expect to get done either.\u003c/p\u003e\n\u003csection class=\"footnotes\" role=\"doc-endnotes\"\u003e\n\u003chr\u003e\n\u003col\u003e\n\u003cli id=\"fn1\" role=\"doc-endnote\"\u003elike metabase, superset, redash etc\u003ca href=\"#fnref1\" class=\"footnote-back\" role=\"doc-backlink\"\u003e↩\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/section\u003e\n"}},"__N_SSG":true},"page":"/[...posts]","query":{"posts":["code","a-distributed-link-shortner"]},"buildId":"vLj-h1l1iYxo80BnxHitK","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>